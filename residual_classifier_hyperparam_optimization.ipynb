{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "@webio": {
      "lastCommId": null,
      "lastKernelId": null
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Lab_1_2_Classifier final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqRRlYiORE1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import pickle as pkl\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix as cm\n",
        "from sklearn.metrics import plot_confusion_matrix as pcm\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J0gLbcLXZ7l",
        "colab_type": "code",
        "outputId": "08633f01-1894-4ac7-bb70-f035d3a652ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder = '/content/drive/My Drive/601R/lab1/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpiu54v2RE1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ8bGbeIRE2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TinyImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Load the Image Dataset and labels\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, kind=\"train\"):\n",
        "        self.kind = kind\n",
        "        root = \"./tiny-imagenet-200/\"\n",
        "        folder = root + kind\n",
        "        trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        self.dataset_folder = torchvision.datasets.ImageFolder(root,transform = trans)\n",
        "        if kind == \"val\":\n",
        "            val = pd.read_csv(folder+\"/val_annotations.txt\", sep=\"\\t\", header=None, names=[\"img\",\"n\",\"x\",\"y\",\"z\",\"w\"])\n",
        "            ids = pd.read_csv(root+\"wnids.txt\", sep=\"\\t\", header=None, names=[\"n\"]).reset_index().sort_values(by=\"n\")\n",
        "            self.labels = dict(val.merge(ids, how=\"left\",on=\"n\")[\"index\"])\n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        img = self.dataset_folder[index]\n",
        "        if self.kind == \"Val\":\n",
        "            label = self.labels[index]\n",
        "        else:\n",
        "            label = img[1]\n",
        "        return img[0], label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBwcHTiWRE2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic Block with 2 layers in it\n",
        "    \"\"\"\n",
        "    expansion = 1\n",
        "    \n",
        "    def __init__(self, in_c, out_c, acti, b_n, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.acti = acti\n",
        "        self.downsample = downsample\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        \n",
        "        if b_n:\n",
        "            bn1 = nn.BatchNorm2d(in_c)\n",
        "            bn2 = nn.BatchNorm2d(out_c)\n",
        "            self.conv1 = nn.Sequential(bn1, self.conv1)\n",
        "            self.conv2 = nn.Sequential(bn2, self.conv2)\n",
        "        \n",
        "        # TODO: need code for dim reduction?\n",
        "        \n",
        "    def forward(self, x):\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "        else:\n",
        "            residual = x\n",
        "        \n",
        "        out = self.conv1(x)\n",
        "        out = self.acti(out)\n",
        "        \n",
        "        out = self.conv2(out)\n",
        "        out += residual\n",
        "        out = self.acti(out)\n",
        "        \n",
        "        return out\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI_k1N0RRE2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Full ResNet Model\n",
        "    \"\"\"\n",
        "    def __init__(self, acti, b_n, weight_init, drop_out, layers=[2,3,3,1], in_c=3):\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        self.drop_out = drop_out\n",
        "        self.acti = acti\n",
        "        self.b_n = b_n\n",
        "        self.inplanes = 64\n",
        "        num_classes = 10\n",
        "        \n",
        "        # First layer\n",
        "        self.conv1 = nn.Conv2d(in_c, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        if b_n:\n",
        "            self.conv1 = nn.Sequential(nn.BatchNorm2d(in_c), self.conv1)\n",
        "            \n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        # Middle layers\n",
        "        self.layer1 = self._make_layer(BasicBlock, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(BasicBlock, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(BasicBlock, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(BasicBlock, 512, layers[3], stride=2)\n",
        "        \n",
        "        # last layer\n",
        "        self.dropout = nn.Dropout2d(p=0.5,inplace=True)\n",
        "            \n",
        "        # Linear Layer\n",
        "        self.linear = nn.Linear(512, num_classes) \n",
        "        \n",
        "        # Weight Initialization\n",
        "        def init_weights(m):\n",
        "            if type(m) == nn.Conv2d:\n",
        "                #Xe Initialization\n",
        "                if(weight_init == 1):\n",
        "                    nn.init.xavier_uniform_(m.weight)\n",
        "                else: #Orthogonal Optimization\n",
        "                    nn.init.orthogonal_(m.weight)\n",
        "\n",
        "        self.apply(init_weights)\n",
        "            \n",
        "        \n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                                    kernel_size=1, stride=stride, bias=False)\n",
        "            if self.b_n:\n",
        "                downsample = nn.Sequential(\n",
        "                    downsample,\n",
        "                    nn.BatchNorm2d(planes * block.expansion),\n",
        "                )\n",
        "            \n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, self.acti, self.b_n, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, self.acti, self.b_n))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.acti(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        if self.drop_out:\n",
        "            x = self.dropout(x)\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiwgXth_RE2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_rnn(filename, dataset, \n",
        "              epochs, batch_size, \n",
        "              acti, batch_norm, \n",
        "              lr, lr_scheduler, \n",
        "              weight_init, drop_out,\n",
        "              loss_func):\n",
        "    \n",
        "    model = RNN(acti, batch_norm, weight_init, drop_out)\n",
        "\n",
        "    model = model.cuda()\n",
        "    \n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    loss_func = loss_func.cuda()\n",
        "        \n",
        "    loader = DataLoader(dataset, batch_size=batch_size, pin_memory=True, shuffle=True)\n",
        "\n",
        "    if lr_scheduler:\n",
        "        step_size = 4*len(loader)\n",
        "        clr = cyclical_lr(step_size)\n",
        "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, [clr])\n",
        "    \n",
        "    total_losses = []\n",
        "    e_losses = []\n",
        "    \n",
        "    for e in range(epochs):\n",
        "    \n",
        "        losses = []\n",
        "        \n",
        "        for i, (img, label) in enumerate(loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            y = model(img.cuda())\n",
        "\n",
        "            loss = loss_func(y, label.cuda())\n",
        "            loss.backward()\n",
        "            losses.append(loss.item())\n",
        "            \n",
        "            optimizer.step()\n",
        "\n",
        "            # adjust learning rate if set\n",
        "            if lr_scheduler is not None:\n",
        "                scheduler.step()\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                total_losses.append(np.mean(losses))\n",
        "\n",
        "        e_losses.append(np.mean(losses))\n",
        "        print(\"--------Epoch \", e ,\"--------- Loss:\", e_losses[-1])\n",
        "\n",
        "    torch.save(model.state_dict(), folder + filename + \".pt\")\n",
        "    return model, e_losses, total_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6r2q3oIRE22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss(filename, losses, total, batch_size):\n",
        "    \n",
        "    plt.plot(range(len(losses)), losses)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Loss Per Epoch\")\n",
        "    \n",
        "    plt.savefig(filename + \"_e_loss.jpg\")\n",
        "    plt.savefig(folder + filename + \"_e_loss.jpg\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(np.arange(len(total))*50, total)\n",
        "    plt.xlabel(\"Batch(\" + str(batch_size) +\")\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Loss Curve\")\n",
        "    \n",
        "    plt.savefig(folder + filename + \"_t_loss.jpg\")\n",
        "    plt.show()\n",
        "    \n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AITjdnKRE25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confusion_matrix(filename, model, plot=False):\n",
        "    model.eval()\n",
        "    num_classes = 10\n",
        "    matrix = np.empty((num_classes,num_classes))\n",
        "    \n",
        "    val_data = torchvision.datasets.CIFAR10(folder,train=False,transform=transform_train)\n",
        "    \n",
        "    loader = DataLoader(val_data, batch_size=1)\n",
        "\n",
        "    guesses = []\n",
        "    labels = []\n",
        "    \n",
        "    for i, (img, label) in enumerate(loader):\n",
        "        # get model guess\n",
        "        y = model(img.cuda())\n",
        "        guesses.append(y.argmax().item())\n",
        "        labels.append(label.item())\n",
        "\n",
        "    acc = sum(np.array(guesses) == np.array(labels))/len(guesses)\n",
        "    print(\"Accuracy:\", acc)\n",
        "\n",
        "    # save accuracy\n",
        "    acc_file = folder + filename+\"_acc.txt\"\n",
        "    open(acc_file, 'w').write(str(acc))\n",
        "        \n",
        "    conf_matrix = cm(labels,guesses)\n",
        "\n",
        "    if plot:\n",
        "        plt.figure(figsize = (10,7))\n",
        "        sn.heatmap(conf_matrix, annot=True)\n",
        "        plt.title(\"Confusion Matrix for CIFAR10\")\n",
        "        plt.ylabel(\"True Class\")\n",
        "        plt.xlabel(\"Predicted Class\")\n",
        "        plt.savefig(folder + filename + \"_confusion.jpg\")\n",
        "        plt.show()\n",
        "    \n",
        "    return conf_matrix, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6gVDaYQRE27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(filename=\"model\", plot_l=False, plot_cm=False,\n",
        "         epochs=20, batch_size=256,\n",
        "         acti=nn.ReLU(), batch_norm=False, \n",
        "         lr=.001, lr_scheduler=None, \n",
        "         weight_init=1, drop_out=False,\n",
        "         loss_func=nn.CrossEntropyLoss()):\n",
        "    \n",
        "    model_file = folder + filename+\".pt\"\n",
        "    if os.path.exists(model_file):\n",
        "        acc_file = folder + filename+\"_acc.txt\"\n",
        "        if os.path.exists(acc_file):\n",
        "            return float(open(acc_file, 'r').readline())\n",
        "        else:\n",
        "            model = RNN(acti, batch_norm, weight_init, drop_out)\n",
        "            model.load_state_dict(torch.load(model_file))\n",
        "            model = model.cuda()\n",
        "            \n",
        "    else:\n",
        "        # train\n",
        "        dataset = torchvision.datasets.CIFAR10(folder, train=True, transform=transform_train)\n",
        "        model, e_losses, total = train_rnn(filename, dataset,\n",
        "                                    epochs, batch_size, \n",
        "                                    acti, batch_norm, \n",
        "                                    lr, lr_scheduler,\n",
        "                                    weight_init, drop_out, loss_func)\n",
        "\n",
        "        if plot_l:\n",
        "            plot_loss(filename, e_losses, total,batch_size)\n",
        "\n",
        "    # confusion matrix\n",
        "    conf_matrix, acc = confusion_matrix(filename, model, plot_cm)\n",
        "    \n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPU1bVP81Ef5",
        "colab_type": "text"
      },
      "source": [
        "## Part (i)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31fOR6I3qn-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LabelSmoothingLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Loss for Label Smoothing\n",
        "    \"\"\"\n",
        "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
        "        super(LabelSmoothingLoss, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.cls = classes\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = pred.log_softmax(dim=self.dim)\n",
        "        with torch.no_grad():\n",
        "            # true_dist = pred.data.clone()\n",
        "            true_dist = torch.zeros_like(pred)\n",
        "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
        "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n",
        "\n",
        "def SELU(x):\n",
        "        \"\"\"\n",
        "            Scaled EUL function\n",
        "        \"\"\"\n",
        "        alpha = 1.6732632423543772848170429916717\n",
        "        scale = 1.0507009873554804934193349852946\n",
        "        return scale * nn.ELU(alpha)(x)\n",
        "\n",
        "def cyclical_lr(stepsize, min_lr=3e-4, max_lr=3e-3):\n",
        "\n",
        "    # Scaler: we can adapt this if we do not want the triangular CLR\n",
        "    scaler = lambda x: 1.\n",
        "\n",
        "    # Lambda function to calculate the LR\n",
        "    lr_lambda = lambda it: min_lr + (max_lr - min_lr) * relative(it, stepsize)\n",
        "\n",
        "    # Additional function to see where on the cycle we are\n",
        "    def relative(it, stepsize):\n",
        "        cycle = math.floor(1 + it / (2 * stepsize))\n",
        "        x = abs(it / stepsize - 2 * cycle + 1)\n",
        "        return max(0, (1 - x)) * scaler(cycle)\n",
        "\n",
        "    return lr_lambda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgIu6d2uXBH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare_hyper_parameters(n_classes=10, plot=True):\n",
        "    \"\"\"\n",
        "\n",
        "        Looks at each of the following hyperparameter/permutation and compares each of them\n",
        "\n",
        "        Activation functions: relu (baseline), leakyrelu, selu, elu, hardshrink\n",
        "        Batchnorm: off (baseline), on (use one batchnorm per residual block)\n",
        "        Label smoothing: off (baseline), on\n",
        "        Learning rate: constant (baseline), CLR\n",
        "        Regularization: off (baseline), dropout\n",
        "        Initialization: uniform(baseline),  xavier/he, orthogonal\n",
        "    \"\"\"\n",
        "    accuracies = []\n",
        "\n",
        "    # # Baseline\n",
        "    accuracies.append(main(filename=\"model_base\"))\n",
        "\n",
        "    # Activation Functions\n",
        "    accuracies.append(main(filename=\"model_selu\", acti=SELU))\n",
        "    accuracies.append(main(filename=\"model_leaky_relu\", acti=nn.LeakyReLU()))\n",
        "    accuracies.append(main(filename=\"model_elu\", acti=nn.ELU()))\n",
        "    accuracies.append(main(filename=\"model_hardshrink\", acti=nn.Hardshrink()))\n",
        "\n",
        "    # Batchnorm and dropout\n",
        "    accuracies.append(main(filename=\"model_batch_norm\", batch_norm=True))\n",
        "    accuracies.append(main(filename=\"model_drop_out\", drop_out=True))\n",
        "    \n",
        "    # learning and label smoothing\n",
        "    accuracies.append(main(filename=\"model_clr_same\", lr_scheduler=True))\n",
        "    accuracies.append(main(filename=\"model_label_smoothing\", loss_func=LabelSmoothingLoss(n_classes)))\n",
        "\n",
        "    # weight initialization\n",
        "    accuracies.append(main(filename=\"model_orthogonal\", weight_init=2))\n",
        "\n",
        "    if plot:\n",
        "        labels = [\"Baseline\", \"SeLU\", \"LeakyReLU\", \"ELU\", \"HardShrink\", \"Batch Norm\", \n",
        "                    \"Drop Out\", \"CLR\", \"Label Smoothing\", \"Orthogonal Weight Init\"]\n",
        "        plt.barh(range(10), accuracies,tick_label=labels)\n",
        "        plt.title(\"Hyperparameter Testing With ResNet on CIFAR10\")\n",
        "        plt.savefig(folder + \"Hyperparams_Bar_Graph.jpg\")\n",
        "        plt.show()\n",
        "\n",
        "    return accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12B_m55FkIll",
        "colab_type": "code",
        "outputId": "c03d10ef-e11d-44f3-9ef3-a2eec48d0a03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "compare_hyper_parameters()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdUAAAEICAYAAAAJGW4GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7091, 0.7155, 0.7226, 0.729, 0.7167, 0.7553, 0.7201, 0.3597, 0.7129, 0.7208]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW99_dD_Vo9X",
        "colab_type": "text"
      },
      "source": [
        "## Part (ii)\n",
        "## Best Combination of Parameters\n",
        "\n",
        "Looking at the accuracies of the different tweaks and hyper parameters in part i, 4-5 combinations of such parameters should be feasible. \n",
        "\n",
        "In general it would be reasonable to try a combination of things with batch norm as batch norm ended up with the highest accuracy of the parameter tweaks.\n",
        "\n",
        "Strategies:\n",
        "* Combine Batch Norm and ELU activation as those were two of highest accuracy measures\n",
        "* Combine Batch Norm with Orthogonal Initialization\n",
        "* Combine Batch Norm, Orthogonal Initialization, and ELU activation\n",
        "* Combine Batch Norm, Orthogonal Initialization, ELU activation, and Label Smoothing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd_Tbhoy0_iq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine_hyper_parameters(plot=True, n_classes=10):\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    accuracies.append(main(filename=\"model_base\"))\n",
        "\n",
        "    accuracies.append(main(filename=\"model_batch_elu\", \n",
        "                           batch_norm=True, acti=nn.ELU()))\n",
        "\n",
        "    accuracies.append(main(filename=\"model_batch_orthog\", \n",
        "                           batch_norm=True, weight_init=2))\n",
        "\n",
        "    accuracies.append(main(filename=\"model_batch_elu_orthog\", \n",
        "                           batch_norm=True, acti=nn.ELU(), weight_init=2))\n",
        "\n",
        "    accuracies.append(main(filename=\"model_batch_elu_orthog_smooth\", \n",
        "                           batch_norm=True, acti=nn.ELU(), \n",
        "                           weight_init=2, loss_func=LabelSmoothingLoss(n_classes)))\n",
        "\n",
        "\n",
        "    if plot:\n",
        "        labels = [\"Baseline\", \"Batch Norm/ELU\", \"Batch Norm/Orthogonal Init\",\n",
        "                    \"Batch Norm/ELU/Orthogonal Init\", \"Batch Norm/ELU/Orthogonal Init/Label Smoothing\"]\n",
        "        plt.barh(range(5), accuracies,tick_label=labels)\n",
        "        plt.title(\"Hyperparameter Combining With ResNet on CIFAR10\")\n",
        "        plt.savefig(folder + \"Hyperparams_Combine_Bar_Graph.jpg\")\n",
        "        plt.show()\n",
        "\n",
        "    return accuracies\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiMbSgbPdBAc",
        "colab_type": "code",
        "outputId": "4c17490c-8aa9-40d7-d352-3995f4894010",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "combine_hyper_parameters()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAEICAYAAABlKUHyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXnnj2WHgAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7091, 0.7743, 0.7587, 0.7608, 0.7538]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7SkIijJjyHL",
        "colab_type": "text"
      },
      "source": [
        "Interestingly enough the batch norm with the ELU without anything else had the highest accuracy."
      ]
    }
  ]
}